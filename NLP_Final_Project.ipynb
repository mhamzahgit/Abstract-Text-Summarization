{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yRzwkGMXVKBj",
    "outputId": "a8262db4-d8b5-4c82-9755-c671e85601f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.1.72)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: WordCloud in /usr/local/lib/python3.7/dist-packages (1.8.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from WordCloud) (1.21.6)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from WordCloud) (7.1.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from WordCloud) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->WordCloud) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->WordCloud) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->WordCloud) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->WordCloud) (1.4.4)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->WordCloud) (4.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->WordCloud) (1.15.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.1)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install contractions\n",
    "!pip install WordCloud\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Juc1sb60mj3a"
   },
   "outputs": [],
   "source": [
    "# conda install nomkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4biDmSvGodJ"
   },
   "source": [
    "# Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b0RKLvkrUjJV"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "import unicodedata\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import STOPWORDS, WordCloud\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import contractions\n",
    "from contractions import contractions_dict\n",
    "\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Embedding, TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9uKyxOKJ0wFn",
    "outputId": "cab028a9-2f0f-4b55-8903-9f5b38e76a80"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
     ]
    }
   ],
   "source": [
    "# Using TPU\n",
    "\n",
    "# detect and init the TPU\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "tf.config.experimental_connect_to_cluster(tpu)\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "\n",
    "# instantiate a distribution strategy\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c_6Y2UIVVRPQ",
    "outputId": "3a9f5dfd-fb08-43ae-d0c2-8afcd3244705"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SlzkV91HVVAT",
    "outputId": "6785cac2-c32f-4645-b362-71b4c6acb02f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1T5yjTUEGvjm"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fSMzm7h2VtpY",
    "outputId": "b3a2f8ad-c93a-45dc-db7a-d48ffe6e1c4f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-254f4ba9-0dca-45cb-8c59-6c4a0e698318\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-254f4ba9-0dca-45cb-8c59-6c4a0e698318')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-254f4ba9-0dca-45cb-8c59-6c4a0e698318 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-254f4ba9-0dca-45cb-8c59-6c4a0e698318');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...  \n",
       "1  Kunal Shah's credit card bill payment platform...  \n",
       "2  New Zealand defeated India by 8 wickets in the...  \n",
       "3  With Aegon Life iTerm Insurance plan, customer...  \n",
       "4  Speaking about the sexual harassment allegatio...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/content/drive/MyDrive/NLP/news_summary_more.csv'\n",
    "df = pd.read_csv(filename, encoding='latin')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "opwKOLkymiU3"
   },
   "outputs": [],
   "source": [
    "df_columns = df.columns.tolist()\n",
    "df_columns.remove('headlines')\n",
    "df_columns.remove('text')\n",
    "df.drop(df_columns, axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the RAM support is only for 12GB, we need to shorten the amount of data that we plan to use.\n",
    "\n",
    "Hence we will be only using the first 35,000 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R64MD4OFWEsY",
    "outputId": "c7b680bc-8c05-40be-d3b1-3094ca870608"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "summary       0\n",
       "reviewText    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df.head(20000)\n",
    "df.columns = ['summary', 'reviewText']\n",
    "df.isnull().sum()\n",
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "V43iBJbwWOca",
    "outputId": "f21d4486-9c48-47d8-a912-70d80c1dca3f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-0868780d-e316-4ec8-9fba-c7d239e53fae\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Edtech startup Springboard raises $9.5 million...</td>\n",
       "      <td>US-based edtech startup Springboard has raised...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Men should learn to do household work: Sushma ...</td>\n",
       "      <td>External Affairs Minister Sushma Swaraj on Thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do bubbles rise in a zig-zag manner?</td>\n",
       "      <td>Air bubbles rise in water due to their buoyanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nick is fine with Mumbai now, it's his other h...</td>\n",
       "      <td>Actress Priyanka Chopra, while talking about h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Woman strangles, buries 14-month-old son with ...</td>\n",
       "      <td>A 20-year-old woman in Maharashtra's Bhiwandi ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0868780d-e316-4ec8-9fba-c7d239e53fae')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-0868780d-e316-4ec8-9fba-c7d239e53fae button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-0868780d-e316-4ec8-9fba-c7d239e53fae');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  Edtech startup Springboard raises $9.5 million...   \n",
       "1  Men should learn to do household work: Sushma ...   \n",
       "2           Why do bubbles rise in a zig-zag manner?   \n",
       "3  Nick is fine with Mumbai now, it's his other h...   \n",
       "4  Woman strangles, buries 14-month-old son with ...   \n",
       "\n",
       "                                          reviewText  \n",
       "0  US-based edtech startup Springboard has raised...  \n",
       "1  External Affairs Minister Sushma Swaraj on Thu...  \n",
       "2  Air bubbles rise in water due to their buoyanc...  \n",
       "3  Actress Priyanka Chopra, while talking about h...  \n",
       "4  A 20-year-old woman in Maharashtra's Bhiwandi ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We can be sure our data has no null values, so it is ready to be preprocessed now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ceHznNAGzW2"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will be removing contractions by expanding them to better understand context\n",
    "\n",
    "## Then we remove punctuations, and remove numbers and special characters, as they don't mean much for us\n",
    "\n",
    "## Lower-casing as there is no need for understanding capitalizations here\n",
    "\n",
    "## and finally we remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lmStVUObWRYq"
   },
   "outputs": [],
   "source": [
    "def preprocess(text,remove_stopwords=True):\n",
    "    \n",
    "    lemmatizer=nltk.stem.wordnet.WordNetLemmatizer()\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "    ## Using Contractions.fix to expand the contractinos that are present in the text\n",
    "    contraction_text= contractions.fix(text)\n",
    "\n",
    "    ## Handling the Punctuation \n",
    "    punctuated_s= re.sub('\\'s', '', contraction_text )\n",
    "    punctuated_appostrophe= re.sub('\\'', '', punctuated_s ) \n",
    "    punctuated_text = re.sub(r\"[^a-z0-9]+\", ' ', punctuated_appostrophe)\n",
    "    non_numbers= re.sub('[0-9]+', '', punctuated_text)\n",
    "\n",
    "    ## Unicode handling by removing unicode characters (e.g emojis)\n",
    "    string_encode = non_numbers.encode('ascii', 'ignore')\n",
    "    string_decode = string_encode.decode()\n",
    "\n",
    "    ## Making the raw-text to lower-case\n",
    "    lower_text = string_decode.lower()\n",
    "     \n",
    "    \n",
    "    ## Removing stop-words \n",
    "    if remove_stopwords== True:\n",
    "      non_stopwords_text = '' \n",
    "\n",
    "      for word in string_decode.split():\n",
    "          if word not in stopwords:\n",
    "              non_stopwords_text+=word + \" \"\n",
    "\n",
    "      return non_stopwords_text\n",
    "      \n",
    "    else:\n",
    "      return string_decode\n",
    "\n",
    "## We don't need the preprocess function to run on all the columns of the dataframe\n",
    "## So we will just be applying this on the Review_Text column\n",
    "\n",
    "##List of cleaned reviews\n",
    "cleaned_reviews=[]\n",
    "for review in df.reviewText:\n",
    "    cleaned_reviews.append(preprocess(review))\n",
    "\n",
    "##List of cleaned review summaries\n",
    "cleaned_review_summaries=[]\n",
    "\n",
    "for summary in df.summary:\n",
    "    cleaned_review_summaries.append(preprocess(summary,remove_stopwords=False))\n",
    "\n",
    "\n",
    "## Make this return tokens so just do non_stopwords_text.tokenize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SIlkBB8EWv3r"
   },
   "outputs": [],
   "source": [
    "##List of cleaned reviews\n",
    "cleaned_reviews=[]\n",
    "for review in df.reviewText:\n",
    "    cleaned_reviews.append(preprocess(review))\n",
    "\n",
    "##List of cleaned review summaries\n",
    "cleaned_review_summaries=[]\n",
    "\n",
    "for summary in df.summary:\n",
    "    cleaned_review_summaries.append(preprocess(summary,remove_stopwords=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DcuH-5bZWxPf"
   },
   "outputs": [],
   "source": [
    "df['reviewText']=cleaned_reviews\n",
    "df['summary']=cleaned_review_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "OgopjtQAbLOi"
   },
   "outputs": [],
   "source": [
    "df.summary = df.summary.apply(lambda x: f'_START_ {x} _END_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "pd9eNk8LbPTh"
   },
   "outputs": [],
   "source": [
    "start_token = 'sostok'\n",
    "end_token = 'eostok'\n",
    "df.summary = df.summary.apply(lambda x: f'{start_token} {x} {end_token}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "U-LgKOpwbUXQ",
    "outputId": "6010e91f-59ba-4f42-f43b-7ad8bbd9ac5b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9fc071e2-a7b4-479f-b5b9-c37e0b844d0e\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81213</th>\n",
       "      <td>sostok _START_  ndia will develop  km stretch ...</td>\n",
       "      <td>ighways ansukh andaviya hursday said ndia deve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10137</th>\n",
       "      <td>sostok _START_  ohit harma plays gully cricket...</td>\n",
       "      <td>ndian cricketer ohit harma shared video wherei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38910</th>\n",
       "      <td>sostok _START_  entral varsity in ihar to adop...</td>\n",
       "      <td>ahatma andhi entral niversity adopt five villa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95271</th>\n",
       "      <td>sostok _START_  ak has links to terrorist grou...</td>\n",
       "      <td>hairman oint hiefs taff eneral oseph unford ue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33805</th>\n",
       "      <td>sostok _START_  hat all do ndian ailways passe...</td>\n",
       "      <td>ailway rotection orce recovered stolen items l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fc071e2-a7b4-479f-b5b9-c37e0b844d0e')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9fc071e2-a7b4-479f-b5b9-c37e0b844d0e button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9fc071e2-a7b4-479f-b5b9-c37e0b844d0e');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                                                 summary  \\\n",
       "81213  sostok _START_  ndia will develop  km stretch ...   \n",
       "10137  sostok _START_  ohit harma plays gully cricket...   \n",
       "38910  sostok _START_  entral varsity in ihar to adop...   \n",
       "95271  sostok _START_  ak has links to terrorist grou...   \n",
       "33805  sostok _START_  hat all do ndian ailways passe...   \n",
       "\n",
       "                                              reviewText  \n",
       "81213  ighways ansukh andaviya hursday said ndia deve...  \n",
       "10137  ndian cricketer ohit harma shared video wherei...  \n",
       "38910  ahatma andhi entral niversity adopt five villa...  \n",
       "95271  hairman oint hiefs taff eneral oseph unford ue...  \n",
       "33805  ailway rotection orce recovered stolen items l...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDToknjLG3e5"
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will visualise the length of summaries to have a better understanding of how to do our sequence padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "WW7qX_zzbV5F",
    "outputId": "f880f25f-ce19-42d9-f3ed-77317593d6dd"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_count = []\n",
    "summary_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for review in df['reviewText']:\n",
    "      text_count.append(len(review.split()))\n",
    "\n",
    "for summary in df['summary']:\n",
    "      summary_count.append(len(summary.split()))\n",
    "\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_count, 'summary':summary_count})\n",
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "x4uzZ7J0blSC"
   },
   "outputs": [],
   "source": [
    "# This is to find the maximum length of length of the sumamry and review text we have\n",
    "review_len = []\n",
    "summary_len = []\n",
    "\n",
    "for review in df['reviewText']:\n",
    "  review_len.append(len(review.split()))\n",
    "\n",
    "for summary in df['summary']:\n",
    "  summary_len.append(len(summary.split()))\n",
    "\n",
    "review_max = max(review_len)\n",
    "summary_max = max(summary_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "dO5UlESybpwi"
   },
   "outputs": [],
   "source": [
    "# select the summary and text between their defined max lens respectively\n",
    "\n",
    "cleaned_text = np.array(df.reviewText)\n",
    "cleaned_summary = np.array(df.summary)\n",
    "\n",
    "short_text = []\n",
    "short_summary = []\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if len(cleaned_text[i].split()) <= review_max and len(\n",
    "        cleaned_summary[i].split()\n",
    "    ) <= summary_max:\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "\n",
    "df = pd.DataFrame({'reviewText': short_text, 'summary': short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "BPOdvGSWcq1z"
   },
   "outputs": [],
   "source": [
    "# Splitting the training and validation sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    np.array(df.reviewText),\n",
    "    np.array(df.summary),\n",
    "    test_size=0.1,\n",
    "    random_state=1,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "pImyAnkdctoi"
   },
   "outputs": [],
   "source": [
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to convert these into integer sequences, and then finally into padded sequences, in order to ensure the vectors are of equal lengths for learning\n",
    "\n",
    "<p>This returns the feature matrix, and process also called vectorization</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BrePXIFFeIgl",
    "outputId": "b04dcec9-39ea-4d4f-d2df-39c7ee30d754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72992\n"
     ]
    }
   ],
   "source": [
    "#convert text sequences into integer sequences\n",
    "x_text2seq_train = x_tokenizer.texts_to_sequences(x_train)\n",
    "x_text2seq_val = x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "# padding upto max_text_len\n",
    "x_padseq_train = pad_sequences(x_text2seq_train, maxlen=review_max, padding='post')\n",
    "x_padseq_test = pad_sequences(x_text2seq_val, maxlen=review_max, padding='post')\n",
    "\n",
    "# if you're not using num_words parameter in Tokenizer then use this\n",
    "x_vocab_size = len(x_tokenizer.word_index) + 1\n",
    "\n",
    "print(x_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GYGM9DDfeLpr",
    "outputId": "54375b24-6159-434c-ec6d-43c8a4a001db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'percent': 66.73, 'total_coverage': 3.73, 'count': 22560, 'total_count': 33810}\n"
     ]
    }
   ],
   "source": [
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "print(y_tokens_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "gvnkvnoufDsb"
   },
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "med4ajdqfGST"
   },
   "outputs": [],
   "source": [
    "#convert text sequences into integer sequences\n",
    "y_text2seq_train = y_tokenizer.texts_to_sequences(y_train)\n",
    "y_text2seq_val = y_tokenizer.texts_to_sequences(y_val)\n",
    "\n",
    "#creating the feature Matrices for Reviews_Train and Reviews_Test\n",
    "y_train_padded = pad_sequences(y_text2seq_train, maxlen=summary_max, padding='post')\n",
    "y_val_padded = pad_sequences(y_text2seq_val, maxlen=summary_max, padding='post')\n",
    "\n",
    "# if you're not using num_words parameter in Tokenizer then use this\n",
    "y_vocab_size = len(y_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S8RuSjuyfLWw",
    "outputId": "9471ff4c-1c21-4d34-c6e3-50a3e17c8451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33811\n"
     ]
    }
   ],
   "source": [
    "print(y_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Sj9ax2HifcxB"
   },
   "outputs": [],
   "source": [
    "# removing summary which only has sostok & eostok\n",
    "def remove_indexes(summary_array):\n",
    "    remove_indexes = []\n",
    "    for i in range(len(summary_array)):\n",
    "        count = 0\n",
    "        for j in summary_array[i]:\n",
    "            if j != 0:\n",
    "                count += 1\n",
    "        if count == 2:\n",
    "            remove_indexes.append(i)\n",
    "    return remove_indexes\n",
    "\n",
    "\n",
    "remove_train_indexes = remove_indexes(y_train_padded)\n",
    "remove_val_indexes = remove_indexes(y_val_padded)\n",
    "\n",
    "y_train_padded = np.delete(y_train_padded, remove_train_indexes, axis=0)\n",
    "x_padseq_train = np.delete(x_padseq_train, remove_train_indexes, axis=0)\n",
    "\n",
    "y_val_padded = np.delete(y_val_padded, remove_val_indexes, axis=0)\n",
    "x_padseq_train = np.delete(x_padseq_train, remove_val_indexes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "XXCdGnbAffoX"
   },
   "outputs": [],
   "source": [
    "latent_dim = 240\n",
    "embedding_dim = 300\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uH0b3r5bG99P"
   },
   "source": [
    "# Creating Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We use a pretrained word-embeddigns model, and inspecific, this one as it is much better at handling the OOV's \n",
    "## compared to otehr models like genshim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3p7C4MjAfsC_",
    "outputId": "8294b6c8-03b8-41ac-b2da-905b572612fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-10 17:57:17--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2022-11-10 17:57:17--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2022-11-10 17:57:18--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: glove.6B.zip.2\n",
      "\n",
      "glove.6B.zip.2        3%[                    ]  25.66M  30.5MB/s               ^C\n",
      "Archive:  glove.6B.zip\n",
      "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "# download glove and unzip it in Notebook.\n",
    "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "!unzip glove*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "fKgpdEmAfiFu"
   },
   "outputs": [],
   "source": [
    "## Code taken sourced https://www.geeksforgeeks.org/pre-trained-word-embedding-using-glove-in-nlp-models/\n",
    "\n",
    "def get_embedding_matrix(tokenizer,vocab_size, embedding_dim):\n",
    "    path = 'glove.6B.300d.txt'\n",
    "\n",
    "    # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix_vocab = np.zeros((vocab_size,embedding_dim))\n",
    "  \n",
    "    with open(filepath, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word]\n",
    "                embedding_matrix_vocab[idx] = np.array(\n",
    "                    vector, dtype=np.float32)[:embedding_dim]\n",
    "  \n",
    "    return embedding_matrix_vocab\n",
    "\n",
    "x_embedding_matrix = get_embedding_matrix(x_tokenizer, x_vocab_size, embedding_dim)\n",
    "y_embedding_matrix = get_embedding_matrix(y_tokenizer, y_vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lyVmCvnkf5RD",
    "outputId": "7058ddfa-f638-4805-f15e-00b01e54c64f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72992, 300)\n",
      "(33811, 300)\n"
     ]
    }
   ],
   "source": [
    "print(x_embedding_matrix.shape)\n",
    "print(y_embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to create our models, and then train them, we begin with the simple unidirectinal model fro LSTM,and then we will implement the Hybrid model, where encoder is bi-directional and decoder is unidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irUItARoHB87"
   },
   "source": [
    "# Model Creation: Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "yzOdAIUkf74f"
   },
   "outputs": [],
   "source": [
    "def build_seq2seq_model_with_just_lstm(embedding_dim, latent_dim, max_text_len, x_vocab_size, y_vocab_size,x_embedding_matrix, y_embedding_matrix):\n",
    " \n",
    "    with tpu_strategy.scope():    \n",
    "\n",
    "                                  ## Encoder\n",
    "        encoder_input = Input(shape=(review_max, ))\n",
    "\n",
    "        # encoder embedding layer\n",
    "        encoder_embedding = layers.Embedding(\n",
    "            input_dim= len(x_vocab_size),\n",
    "            output_dim= embedding_dim,\n",
    "            trainable=True)\n",
    "\n",
    "        encoder_embed = encoder_embedding(encoder_input)\n",
    "\n",
    "        # encoder LSTM layer\n",
    "        encoderLstm = layers.LSTM( name= 'encoderLstm',\n",
    "                                   units=lstm_units, \n",
    "                                   dropout=0.4,\n",
    "                                   return_sequences=True, \n",
    "                                   return_state=True)\n",
    "\n",
    "        x_out, state_h, state_c = encoderLstm(encoder_embed)\n",
    "        encoder_output, *encoder_final_states = encoder_lstm(\n",
    "            encoder_embedding, initial_state=encoder_final_states\n",
    "        )\n",
    "                                ## Decoder\n",
    "\n",
    "        decoder_input = layers.Input(shape=(None, ))\n",
    "\n",
    "        # decoder embedding layer\n",
    "        decoder_embedding_layer = layers.Embedding(\n",
    "                                       input_dim=y_vocab_size, \n",
    "                                       output_dim=embedding_dim, \n",
    "                                       trainable=True)\n",
    "\n",
    "        decoder_embedding = decoder_embedding(decoder_input)\n",
    "\n",
    "        ### decoder LSTM Layer \n",
    "        decoder_lstm = layers.LSTM( name= 'decoder_lstm',\n",
    "                                   units=lstm_units, \n",
    "                                   dropout=0.4,\n",
    "                                   return_sequences=True, \n",
    "                                   return_state=True)\n",
    "        decoder_output, *decoder_final_states = decoder_lstm(decoder_embedding, initial_state=encoder_final_states )\n",
    "\n",
    "        ### dense layers\n",
    "\n",
    "\n",
    "        layer_dense = layers.TimeDistributed(\n",
    "                                              layer=layers.Dense(\n",
    "                                                                  units=y_vocab_size,\n",
    "                                                                  activation='softmax'))\n",
    "        decoder_output = decoder_dense(decoder_output)\n",
    "\n",
    "\n",
    "        ##                                Model\n",
    "        model = models.Model(inputs=[encoder_input, decoder_input],\n",
    "                             outputs=y_out)\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "        model.compile(optimizer=optimizer,\n",
    "                      loss='categorical_crossentropy', \n",
    "                      metrics=['accuracy'])\n",
    "        model.summary()\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'encoder_decoder_input': {\n",
    "                'encoder_input': encoder_input,\n",
    "                'decoder_input': decoder_input\n",
    "            },\n",
    "            'encoder_decoder_output': {\n",
    "                'encoder_output': encoder_output,\n",
    "                'decoder_output': decoder_output\n",
    "            },\n",
    "            'encoder_decoder_states': {\n",
    "                'encoder_final_state': encoder_final_states,\n",
    "                'decoder_final_state': decoder_final_states\n",
    "            },\n",
    "            'decoder_layer': {\n",
    "                'decoder': {\n",
    "                    'embedding': decoder_embedding_layer,\n",
    "                    'last_decoder_lstm': decoder_lstm,\n",
    "                    'dense': decoder_dense\n",
    "                }\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jWK79Up6gphL",
    "outputId": "c21ca1dd-6d4c-460f-d172-a6092cf0a56b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 59)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 59, 300)      21897600    ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 59, 240),    519360      ['embedding[0][0]']              \n",
      "                                 (None, 240),                                                     \n",
      "                                 (None, 240)]                                                     \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 300)    10143300    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 59, 240),    461760      ['lstm[0][0]']                   \n",
      "                                 (None, 240),                                                     \n",
      "                                 (None, 240)]                                                     \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, None, 240),  519360      ['embedding_1[0][0]',            \n",
      "                                 (None, 240),                     'lstm_1[0][1]',                 \n",
      "                                 (None, 240)]                     'lstm_1[0][2]']                 \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 33811)  8148451    ['lstm_2[0][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 41,689,831\n",
      "Trainable params: 19,792,231\n",
      "Non-trainable params: 21,897,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq2seq = build_seq2seq_model_with_just_lstm(embedding_dim, latent_dim, review_max, x_vocab_size, y_vocab_size,x_embedding_matrix, y_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "RV-NHjY0hGOh"
   },
   "outputs": [],
   "source": [
    "## For more structured processing, code sourced from: \n",
    "\n",
    "model = seq2seq['model']\n",
    "\n",
    "encoder_input = seq2seq['encoder_decoder_input']['encoder_input']\n",
    "decoder_input = seq2seq['encoder_decoder_input']['decoder_input']\n",
    "\n",
    "encoder_output = seq2seq['encoder_decoder_output']['encoder_output']\n",
    "decoder_output = seq2seq['encoder_decoder_output']['decoder_output']\n",
    "\n",
    "encoder_final_states = seq2seq['encoder_decoder_states']['encoder_final_state']\n",
    "decoder_final_states = seq2seq['encoder_decoder_states']['decoder_final_state']\n",
    "\n",
    "decoder_embedding_layer = seq2seq['decoder_layer']['decoder']['embedding']\n",
    "last_decoder_lstm = seq2seq['decoder_layer']['decoder']['last_decoder_lstm']\n",
    "decoder_dense = seq2seq['decoder_layer']['decoder']['dense']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ICHz23kQjShW"
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=0.000001, verbose=1),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZknwZeUyg_Sv",
    "outputId": "5e24b056-5fc6-483d-b201-fc06d65ad2ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "87/87 [==============================] - 62s 410ms/step - loss: 4.9368 - accuracy: 0.4155 - val_loss: 4.0377 - val_accuracy: 0.5202 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 3.9973 - accuracy: 0.5156 - val_loss: 3.8225 - val_accuracy: 0.5254 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 14s 158ms/step - loss: 3.8462 - accuracy: 0.5219 - val_loss: 3.7174 - val_accuracy: 0.5301 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 3.7359 - accuracy: 0.5270 - val_loss: 3.6213 - val_accuracy: 0.5354 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 3.6298 - accuracy: 0.5315 - val_loss: 3.5273 - val_accuracy: 0.5397 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 3.5078 - accuracy: 0.5365 - val_loss: 3.4279 - val_accuracy: 0.5428 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 3.3868 - accuracy: 0.5414 - val_loss: 3.3349 - val_accuracy: 0.5471 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 14s 156ms/step - loss: 3.2779 - accuracy: 0.5461 - val_loss: 3.2315 - val_accuracy: 0.5538 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 3.1823 - accuracy: 0.5508 - val_loss: 3.1600 - val_accuracy: 0.5575 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 3.0945 - accuracy: 0.5552 - val_loss: 3.0917 - val_accuracy: 0.5613 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 3.0154 - accuracy: 0.5593 - val_loss: 3.0397 - val_accuracy: 0.5649 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 13s 148ms/step - loss: 2.9435 - accuracy: 0.5633 - val_loss: 2.9905 - val_accuracy: 0.5679 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 2.8790 - accuracy: 0.5670 - val_loss: 2.9451 - val_accuracy: 0.5713 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 2.8184 - accuracy: 0.5704 - val_loss: 2.9064 - val_accuracy: 0.5739 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 2.7635 - accuracy: 0.5738 - val_loss: 2.8692 - val_accuracy: 0.5767 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 2.7101 - accuracy: 0.5773 - val_loss: 2.8394 - val_accuracy: 0.5788 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 12s 143ms/step - loss: 2.6623 - accuracy: 0.5803 - val_loss: 2.8172 - val_accuracy: 0.5799 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 2.6159 - accuracy: 0.5835 - val_loss: 2.7878 - val_accuracy: 0.5825 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 2.5730 - accuracy: 0.5864 - val_loss: 2.7665 - val_accuracy: 0.5847 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 2.5334 - accuracy: 0.5890 - val_loss: 2.7609 - val_accuracy: 0.5839 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 2.4943 - accuracy: 0.5918 - val_loss: 2.7286 - val_accuracy: 0.5873 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 2.4581 - accuracy: 0.5945 - val_loss: 2.7143 - val_accuracy: 0.5880 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 2.4224 - accuracy: 0.5970 - val_loss: 2.6923 - val_accuracy: 0.5910 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 2.3903 - accuracy: 0.5993 - val_loss: 2.6799 - val_accuracy: 0.5925 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 2.3585 - accuracy: 0.6015 - val_loss: 2.6634 - val_accuracy: 0.5938 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 2.3281 - accuracy: 0.6041 - val_loss: 2.6545 - val_accuracy: 0.5943 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 2.2996 - accuracy: 0.6061 - val_loss: 2.6477 - val_accuracy: 0.5939 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 2.2731 - accuracy: 0.6082 - val_loss: 2.6425 - val_accuracy: 0.5941 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 2.2463 - accuracy: 0.6104 - val_loss: 2.6228 - val_accuracy: 0.5979 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 2.2215 - accuracy: 0.6122 - val_loss: 2.6152 - val_accuracy: 0.5981 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 2.1966 - accuracy: 0.6143 - val_loss: 2.6143 - val_accuracy: 0.5973 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 2.1735 - accuracy: 0.6163 - val_loss: 2.6164 - val_accuracy: 0.5962 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 2.1505 - accuracy: 0.6183 - val_loss: 2.6011 - val_accuracy: 0.5997 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 2.1283 - accuracy: 0.6202 - val_loss: 2.5996 - val_accuracy: 0.5985 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 2.1067 - accuracy: 0.6220 - val_loss: 2.6045 - val_accuracy: 0.5978 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 2.0860 - accuracy: 0.6239 - val_loss: 2.5987 - val_accuracy: 0.5986 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 2.0666 - accuracy: 0.6257 - val_loss: 2.5842 - val_accuracy: 0.6009 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 2.0470 - accuracy: 0.6273 - val_loss: 2.5750 - val_accuracy: 0.6026 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 2.0290 - accuracy: 0.6292 - val_loss: 2.5862 - val_accuracy: 0.5995 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 2.0107 - accuracy: 0.6310 - val_loss: 2.5716 - val_accuracy: 0.6036 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 1.9936 - accuracy: 0.6324 - val_loss: 2.5665 - val_accuracy: 0.6034 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 1.9764 - accuracy: 0.6342 - val_loss: 2.5725 - val_accuracy: 0.6015 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 1.9598 - accuracy: 0.6358 - val_loss: 2.5624 - val_accuracy: 0.6048 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 1.9443 - accuracy: 0.6378 - val_loss: 2.5625 - val_accuracy: 0.6044 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 1.9285 - accuracy: 0.6393 - val_loss: 2.5596 - val_accuracy: 0.6048 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 1.9118 - accuracy: 0.6409 - val_loss: 2.5589 - val_accuracy: 0.6048 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 1.8984 - accuracy: 0.6421 - val_loss: 2.5573 - val_accuracy: 0.6053 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 1.8836 - accuracy: 0.6439 - val_loss: 2.5677 - val_accuracy: 0.6025 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "87/87 [==============================] - ETA: 0s - loss: 1.8688 - accuracy: 0.6454\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 1.8688 - accuracy: 0.6454 - val_loss: 2.5612 - val_accuracy: 0.6049 - lr: 0.0010\n",
      "Epoch 49: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [x_padseq_train, y_train_padded[:, :-1]],\n",
    "    \n",
    "    y_train_padded.reshape(y_train_padded.shape[0], y_train_padded.shape[1], 1)[:, 1:],\n",
    "    epochs=num_epochs,\n",
    "    \n",
    "    ## TPU processing for ML Fitting\n",
    "    batch_size=128 * tpu_strategy.num_replicas_in_sync,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(\n",
    "        [x_val_padded, y_val_padded[:, :-1]],\n",
    "        y_val_padded.reshape(y_val_padded.shape[0], y_val_padded.shape[1], 1)[:, 1:]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "oXUp4x4nRYbF"
   },
   "outputs": [],
   "source": [
    "## To save the model and not requiring to train it again once session closes\n",
    "\n",
    "import pickle\n",
    "pickle.dump(history, open('modelLSTM.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaNYVSH0f_dJ"
   },
   "outputs": [],
   "source": [
    "# ## Loading the saved model\n",
    "\n",
    "# import pickle\n",
    "# with open('modelLSTM.pkl' , 'rb') as f:\n",
    "#     history = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vetsl2NOHVRI"
   },
   "source": [
    "# Model Inference: Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "5RO5lA-GhBTD"
   },
   "outputs": [],
   "source": [
    "# Next, lets build the dictionary to convert the index to word for target and source vocabulary:\n",
    "target_index = y_tokenizer.index_word\n",
    "word_index = x_tokenizer.index_word\n",
    "target_word_index = y_tokenizer.word_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "azbOJAQxiYic"
   },
   "outputs": [],
   "source": [
    "## Code taken from https://stackoverflow.com/questions/60697843/tensorflow-keras-bidirectional-lstm-for-text-summarization\n",
    "\n",
    "def build_seq2seq_model_with_just_lstm_inference(max_text_len, latent_dim, encoder_input, encoder_output, encoder_final_states, decoder_input, decoder_output,decoder_embedding_layer, decoder_dense, last_decoder_lstm):\n",
    "    lstm_hidden_layers=latent_dim\n",
    "    review_max=max_text_len\n",
    "    encoder_state_1 = encoder_input\n",
    "    encoder_state_2 = encoder_output\n",
    "    \n",
    "    encoder_model = Model(inputs=encoder_state_1, outputs=[encoder_state_2] + encoder_final_states)\n",
    "    decoder_h = Input(shape=(lstm_hidden_layers, ))\n",
    "    decoder_c = Input(shape=(lstm_hidden_layers, ))\n",
    "    decoder_hidden_state = Input(shape=(review_max, lstm_hidden_layers))\n",
    "    \n",
    "    decoder_state_1=decoder_input\n",
    "    decoder_state_2= decoder_output\n",
    "    \n",
    "    # Get the embeddings of the decoder sequence\n",
    "    decoder_embedding = decoder_embedding_layer(decoder_state_1)\n",
    "\n",
    "## In order to get the state from the previous state, we set initial state of decoder as initial state of decoder\n",
    "    decoder_output, *decoder_states = last_decoder_lstm(\n",
    "        decoder_embedding,\n",
    "        initial_state=[decoder_h, decoder_c])\n",
    "    \n",
    "    decoder_state_2 = decoder_dense(decoder_state_2)\n",
    "\n",
    "    decoder_model = Model(\n",
    "        [decoder_state_1] + [decoder_hidden_state, decoder_h, decoder_c], \n",
    "        [decoder_state_2] + decoder_states\n",
    "    )\n",
    "\n",
    "    return (encoder_model, decoder_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jUHNRCsFic0L",
    "outputId": "c991b6f1-82d4-4dd6-e47c-b807df850e83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 59)]              0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 59, 300)           21897600  \n",
      "                                                                 \n",
      " lstm (LSTM)                 [(None, 59, 240),         519360    \n",
      "                              (None, 240),                       \n",
      "                              (None, 240)]                       \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               [(None, 59, 240),         461760    \n",
      "                              (None, 240),                       \n",
      "                              (None, 240)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,878,720\n",
      "Trainable params: 981,120\n",
      "Non-trainable params: 21,897,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model, decoder_model = build_seq2seq_model_with_just_lstm_inference( review_max, latent_dim, encoder_input, \n",
    "                                                                            encoder_output,encoder_final_states, decoder_input, decoder_output,decoder_embedding_layer, \n",
    "                                                                            decoder_dense, last_decoder_lstm)\n",
    "\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxW1m5gLir6R",
    "outputId": "8b4ea22e-3783-4ca2-85bf-a0c0e8480832"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, None, 300)    10143300    ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 240)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 240)]        0           []                               \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)                  [(None, None, 240),  519360      ['embedding_1[1][0]',            \n",
      "                                 (None, 240),                     'input_3[0][0]',                \n",
      "                                 (None, 240)]                     'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)           [(None, 59, 240)]    0           []                               \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, None, 33811)  8148451    ['lstm_2[1][0]']                 \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,811,111\n",
      "Trainable params: 18,811,111\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6k4dBR3riycS",
    "outputId": "73bc3e46-bd23-4313-a4aa-ab29bd7d8cd3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, None, 300) dtype=float32 (created by layer 'embedding_1')>,\n",
       " <KerasTensor: shape=(None, 240) dtype=float32 (created by layer 'lstm_1')>,\n",
       " <KerasTensor: shape=(None, 240) dtype=float32 (created by layer 'lstm_1')>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_model.layers[-3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "SdnV1UYSi2-m"
   },
   "outputs": [],
   "source": [
    "def decode_sequence_seq2seq_model_with_just_lstm(input_sequence, encoder_model, decoder_model):\n",
    "    # Encode the input as state vectors.\n",
    "    enoceder_output, encoder_h, encoder_c = encoder_model.predict(input_sequence)\n",
    "\n",
    "    targetSequence = np.zeros((1, 1))\n",
    "    targetSequence[0, 0] = target_word_index[start_token]\n",
    "\n",
    "    stop = False\n",
    "    decoded = ''\n",
    "\n",
    "    while not stop:\n",
    "        output_words, h, c = decoder_model.predict(\n",
    "            [targetSequence] + [enoceder_output, encoder_h, encoder_c]\n",
    "        )\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_words[0, -1, :])\n",
    "        sampled_token = target_index[sampled_token_index]\n",
    "\n",
    "        if sampled_token != end_token:\n",
    "            decoded += ' ' + sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == end_token) or (len(decoded.split()) >= (summary_max - 1)):\n",
    "            stop = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        targetSequence = np.zeros((1, 1))\n",
    "        targetSequence[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        encoder_h, encoder_c = h, c\n",
    "\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "uOwgof1ii7N-"
   },
   "outputs": [],
   "source": [
    "def sequence2summary(inputSequence):\n",
    "    summary = ''\n",
    "    for i in inputSequence:\n",
    "        if ((i != 0 and i != target_word_index[start_token]) and(i != target_word_index[end_token])):\n",
    "            summary = summary + target_index[i] + ' '\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "mJ0MbRSni91r"
   },
   "outputs": [],
   "source": [
    "def sequence2text(inputSequence):\n",
    "    summary = ''\n",
    "    for i in inputSequence:\n",
    "        if i != 0:\n",
    "            summary = summary + reverse_source_word_index[i] + ' '\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "_fKVrSzZjFru"
   },
   "outputs": [],
   "source": [
    "def textPrediction(sample, decode_sequence, encoder_model, decoder_model):\n",
    "    original_text = sample\n",
    "    sample = preprocess(sample)  # generator\n",
    "    tokens = original_text.split()\n",
    "    \n",
    "    if len(tokens) <= review_max:\n",
    "        sample = preprocess(text)\n",
    "        \n",
    "        ## Adding the Start and end tokens in the sample text\n",
    "        sample = f'_START_ {sample} _END_'\n",
    "        \n",
    "        ## To account for certiain errors in indertifying the _START_ and _END_\n",
    "        sample = f'{start_token} {text} {end_token}'\n",
    "\n",
    "        sequence = x_tokenizer.texts_to_sequences([' '.join(tokens)])\n",
    "        paddedSequence = pad_sequences(sequence, maxlen=review_max, padding='post')\n",
    "        predictedSummary = decode_sequence(paddedSequence.reshape(1, review_max), encoder_model, decoder_model)\n",
    "        \n",
    "        return predictedSummary\n",
    "    \n",
    "    else:\n",
    "        predictedSummary = ''\n",
    "        while len(tokens) % review_max == 0:\n",
    "            tokens.append('')\n",
    "\n",
    "        lst_i = review_max\n",
    "        for i in range(0, len(tokens), review_max):\n",
    "            _text_list = original_text.split()[i:i + lst_i]\n",
    "            _text = ' '.join(_text_list)\n",
    "            _text = ' '.join(_text.split())  \n",
    "            _text = preprocess (_text)\n",
    "            _text = f'_START_ {_text} _END_'\n",
    "            _text = f'{start_token} {_text} {end_token}'\n",
    "            \n",
    "            _seq = x_tokenizer.texts_to_sequences([_text])\n",
    "            _padded = pad_sequences(_seq, maxlen=review_max, padding='post')\n",
    "            _pred = decode_sequence(_padded.reshape(1, review_max), encoder_model, decoder_model)\n",
    "            predictedSummary += ' ' + ' '.join(_pred.split()[1:-2])\n",
    "            predictedSummary = ' '.join(predictedSummary.split())\n",
    "\n",
    "        return predictedSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZzL3sKlDvfYa",
    "outputId": "feb94f79-18ec-43d7-beaa-a7120dc67ac1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(summary_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhrOvfJRHeJm"
   },
   "source": [
    "# Model Evaluation: Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6FakWrkajQmv",
    "outputId": "0a265d90-6108-42b7-cbeb-e40b46079f62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 News:  ata roup abur ndia among suitors selected second round bidding raft einz ndia sale n addition omplan product ndian businesses reportedly sold include lucon energy drink ycil talcum powder ampriti ghee raft einz seeking billion assets reports added \n",
      "Original summary:  start ata abur among bidders for raft einz ndia sale eport end \n",
      "1/1 [==============================] - 1s 934ms/step\n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 103ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Predicted summary:   start ata roup to sell majority stake in ndia in ndia end\n",
      "\n",
      "# 2 News:  x world number one tennis player lie astase used nicknamed asty arrested twice within six hours omania riday year old first arrested suspicion driving car drunk refusing take reathalyzer test later released e later arrested going red light scooter \n",
      "Original summary:  start x world no tennis player asty arrested twice in day end \n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "Predicted summary:   start year old world no urray arrested for drunk driving end\n",
      "\n",
      "# 3 News:  esla lon usk disclosed automaker fired employees last month standards high believe mean people e added employees meet company high standards usk added journalists written articles firings without providing context ashamed \n",
      "Original summary:  start ired employees because our standards are high lon usk end \n",
      "1/1 [==============================] - 0s 198ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Predicted summary:   start esla employees told to fire risk of esla employees end\n",
      "\n",
      "# 4 News:  early medicines low middle income countries including ndia substandard falsified orld ealth rganisation report showed uesday ot waste money substandard falsified medical products cause serious illness even death said added products contribute antimicrobial resistance drug resistant infections \n",
      "Original summary:  start ndia among countries where drugs are substandard end \n",
      "1/1 [==============================] - 0s 213ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Predicted summary:   start ndia has least drugs in ndia by eport end\n",
      "\n",
      "# 5 News:  ardik andya took outh frican wickets hosts ended day two first est aturday leading ndia runs arlier andya slammed help ndia score response outh frica first innings eanwhile ernon hilander became seventh outh frican take est wickets home \n",
      "Original summary:  start andya follows his with wickets as end ay at end \n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Predicted summary:   start andya breaks down by runs in a day after losing vs indies end\n",
      "\n",
      "# 6 News:  alayalam actress anju arrier denied reports stated going campaign ongress party erala ahead ok abha elections actress said approached ongress affiliations political party arlier reports suggested anju asked join party senior party leaders \n",
      "Original summary:  start alayalam actress anju denies campaigning for ongress end \n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Predicted summary:   start angana denies reports of quitting as her party end\n",
      "\n",
      "# 7 News:  nited tates resident onald rump used acebook page promote sale rump campaign merchandise lack riday offer also repeated witter account epublican ational ommittee eanwhile ake merica reat gain hats fight fake news stickers sale hop donaldjtrump com proceeds going rump campaign \n",
      "Original summary:  start rump uses page to promote sale on rump merchandise end \n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "Predicted summary:   start rump campaign to sell fake news of anti rump campaign end\n",
      "\n",
      "# 8 News:  ank reportedly planning appoint andeep akhshi rudential ife bank interim replacing handa ochhar bank may ask ochhar go leave internal investigation conflict interest allegations completed reports said akhshi chief life insurance arm since ugust \n",
      "Original summary:  start ife chief to be made ank interim eport end \n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Predicted summary:   start ank to set up panel to decide on es ank eports end\n",
      "\n",
      "# 9 News:  least jawans police personnel injured uesday stones pelted encounter forces terrorists udgam ashmir least three stone pelters killed retaliatory firing one soldier received bullet injuries security forces earlier launched operation nab terrorists later became encounter \n",
      "Original summary:  start jawans cops injured due to stone pelting in ashmir end \n",
      "1/1 [==============================] - 0s 155ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Predicted summary:   start jawans martyred in attack on ashmir firing in ashmir end\n",
      "\n",
      "# 10 News:  ugust mark day humanity annual demand natural resources exceed planet provide year date arrived two days sooner last year according lobal ootprint etwork day marked arth vershoot ay moved late eptember ugust \n",
      "Original summary:  start umans used year worth of arth resources in months tudy end \n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Predicted summary:   start arth could be observed today in days end\n",
      "\n",
      "# 11 News:  undreds people killed around displaced month thiopia clashes country romo omali ethnic groups government said onday clashes erupted earlier month following killing two officials romia region omali regional forces national task force set displaced \n",
      "Original summary:  start undreds killed in ethnic clashes in thiopia end \n",
      "1/1 [==============================] - 0s 156ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Predicted summary:   start killed in clashes in fghanistan end\n",
      "\n",
      "# 12 News:  nformation nearly crore citizens amounting population leaked data analytics company hired develop strategies epublican arty ahead presidential elections data stolen company eep oot nalytics included citizens contact information addresses birthdays among things \n",
      "Original summary:  start ata on citizens leaked from epublican hired company end \n",
      "1/1 [==============================] - 0s 153ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Predicted summary:   start acebook spent crore in data breach in ndia end\n",
      "\n",
      "# 13 News:  oogle denied launched aps app hina reports suggested app made accessible first time country aps accessible desktop years oogle said adding official presence ndroid app stores country oogle flagship earch option banned hina \n",
      "Original summary:  start oogle denies report of launching aps in hina for st time end \n",
      "1/1 [==============================] - 0s 154ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Predicted summary:   start hina denies app that showed news of its first app end\n",
      "\n",
      "# 14 News:  alman han starrer upcoming film ubelight release une announced ollywood trade analyst aran darsh film set backdrop war ndia hina ubelight directed abir han also star hinese actress hu hu hah ukh han seen cameo role film \n",
      "Original summary:  start elease date of alman han film ubelight announced end \n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Predicted summary:   start elease date of alman han starrer ubelight announced end\n",
      "\n",
      "# 15 News:  entley released billion pixel image luxury sports sedan lying pur taken camera suspended metres ayan ower one ubai tallest buildings derived technology used image took hours frames create zoomed till letter clearly visible car \n",
      "Original summary:  start entley takes billion pixel image of its car end \n",
      "1/1 [==============================] - 0s 189ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "Predicted summary:   start orsche worth bn in hina unveils new ad featuring end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing on training data\n",
    "for i in range(0, 15):\n",
    "    print(f\"# {i+1} News: \", sequence2text(x_padseq_train[i]))\n",
    "    print(\"Original summary: \", sequence2summary(y_train_padded[i]))\n",
    "    print(\"Predicted summary: \", decode_sequence_seq2seq_model_with_just_lstm(x_padseq_train[i].reshape(1, review_max), encoder_model,decoder_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "_Mnj-O73akof"
   },
   "outputs": [],
   "source": [
    "# ## writing text down in two files which will then be compared to calculate rouge score for evaluation\n",
    "for i in range(0,y_train.shape[0]):\n",
    "\n",
    "    training_file = open(\"train.txt\", \"a\")\n",
    "    training_file.write(sequence2text(x_padseq_train[i])+'\\n')\n",
    "\n",
    "    prediction_file = open(\"predictionLSTM.txt\", \"a\")\n",
    "    prediction_file.write(sequence2text(decode_sequence_seq2seq_model_with_just_lstm( x_padseq_train[i].reshape(1, review_max), encoder_model,decoder_model)+'\\n'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSfFlyjPjxk2",
    "outputId": "67308808-9f85-44e8-c6b4-6c8877c4dd4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 News:  group lawyers representing teachers students three schools alifornia sued state dragging nation literacy education lawsuit stated lowest performing school alifornia state failed adopt adequate plan tackle issue lawyer said \n",
      "Original summary:  start alifornia sued for dragging down in literacy end \n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Predicted summary:   start erala schools to pay for students who slammed for teaching end\n",
      "\n",
      "# 2 News:  urugram based logistics startup raised million eries funding round valuation around million according reports xisting investors artners arburg incus participated startup funding round reports added ounded manages long haul logistics services caters sectors pharmaceuticals e commerce \n",
      "Original summary:  start tartup raises mn at mn valuation eport end \n",
      "1/1 [==============================] - 0s 216ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "Predicted summary:   start intech startup raises mn in eries funding in eries end\n",
      "\n",
      "# 3 News:  elhi headquartered e learning platform raised million online classifieds company nfo dge new round funding also increase nfo dge stake ounded avan hauhan itesh emrajani delivers online study content assessment modules school students kindergarten class th \n",
      "Original summary:  start learning platform raises million end \n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Predicted summary:   start nline quiz startup ai raises million end\n",
      "\n",
      "# 4 News:  ourtney ovak fan franchise allas avericks got chance score basket half line successfully avericks match ntonio purs aturday ovak converted shot first attempt new inch television also got celebrate shot avericks player irk owitzki \n",
      "Original summary:  start emale basketball fan scores basket from half court wins end \n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Predicted summary:   start an td player scores yard goal in seconds end\n",
      "\n",
      "# 5 News:  amil adu government seeking permanent closure edanta terlite plant uticorin district official andeep anduri said hursday government position clear added comes least people died police firing protesting plant seeking closure environmental health concerns \n",
      "Original summary:  start amil adu seeks permanent closure of terlite plant end \n",
      "1/1 [==============================] - 0s 186ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Predicted summary:   start amil adu govt to shut down terlite plant in amil adu end\n",
      "\n",
      "# 6 News:  ollywood actor anveer ingh posted selfie former ndian captain honi called greatest post ood imes ahi hai mahi reatest read post caption ollywood personalities including rjun apoor onakshi inha mrita rora others also liked picture posted anveer \n",
      "Original summary:  start anveer ingh posts selfie with honi calls him greatest end \n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Predicted summary:   start honi shares throwback picture with ak on his birthday end\n",
      "\n",
      "# 7 News:  elgium arliament cut allowance rince aurent attending hinese diplomatic event naval uniform without government permission allowance cut lakh lawmakers approved cut nearly crore annual allowance rince urged reducing allowance claiming family preventing becoming financially independent \n",
      "Original summary:  start elgian rince allowance cut by over unofficial visit end \n",
      "1/1 [==============================] - 0s 181ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Predicted summary:   start cuts salaries of duty on their first salary cut end\n",
      "\n",
      "# 8 News:  tating ongress added prefix andit former awaharlal ehru name yan ev huja riday said ehru andit ne ate beef pork cannot andit ajasthan also accused ongress party contesting elections name casteism \n",
      "Original summary:  start ehru ate beef and pork he cannot be andit end \n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Predicted summary:   start ill not be renamed as new notes khilesh adav end\n",
      "\n",
      "# 9 News:  hief ohan hagwat unday said people respect cows devote rearing cows resort violence even sentiments deeply hurt hagwat earlier backed arendra odi views condemning violence name cow protection otably around cases cow related violence recorded far \n",
      "Original summary:  start hose who respect cows do not resort to violence hief end \n",
      "1/1 [==============================] - 0s 192ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "Predicted summary:   start eople are cows if they are not a cow slaughter end\n",
      "\n",
      "# 10 News:  exican resident ndr anuel pez brador said debate resident onald rump proposed wall along exico border stop illegal migration internal matter e called issue related electoral politics e convincing government best thing develop entral merica exico added \n",
      "Original summary:  start rump border wall debate internal matter exico resident end \n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Predicted summary:   start rump calls for illegal migration bama end\n",
      "\n",
      "# 11 News:  leader aveen body recovered car kidnapped money later burnt alive allegedly boyfriend police said prime accused ayyab ureshi homosexual relationship allegedly video basis forcing ayyab stay rented flat \n",
      "Original summary:  start leader burnt alive by alleged boyfriend he blackmailed end \n",
      "1/1 [==============================] - 0s 179ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Predicted summary:   start leader found dead in car with family in aryana end\n",
      "\n",
      "# 12 News:  fter took lead arnataka ssembly elections party arnataka handle tweeted ope learned humility eferring ongress candidate iddaramaiah trailing hamundeshwari seat leading adami seat added adami chosen safe option hamundeshwari bound go \n",
      "Original summary:  start ope you have learned humility to ong on taka polls end \n",
      "1/1 [==============================] - 0s 196ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Predicted summary:   start ongress has lost a party in polls khilesh on hah end\n",
      "\n",
      "# 13 News:  undreds unjab government employees received double salary month ctober due technical glitch software government treasury department istrict treasury officer aini sent notice asking employees withdraw extra amount would taken back n mritsar alone crore excess payment made \n",
      "Original summary:  start unjab govt staff receive double salary will have to return it end \n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Predicted summary:   start ovt cuts salaries of employees over unpaid dues end\n",
      "\n",
      "# 14 News:  eading almost double votes received rival candidate adhusudhanan former leader hinakaran said mma constituency hey decided mma successor successor people chosen laiming late amil adu ayalalithaa wishes hinakaran said workers also support \n",
      "Original summary:  start eople have chosen mma successor hinakaran end \n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "Predicted summary:   start ne candidate will be given to win seats in taka end\n",
      "\n",
      "# 15 News:  ctor amir han said choice films want work depends emotional interest story e added follow heart far creative decisions go choice never affected success previous films amir said measure films business \n",
      "Original summary:  start y film choices based on emotional interest in story amir end \n",
      "1/1 [==============================] - 0s 190ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Predicted summary:   start o not want to work in my films as a film amir han end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing on validation data\n",
    "for i in range(0, 15):\n",
    "    print(f\"# {i+1} News: \", sequence2text(x_val_padded[i]))\n",
    "    print(\"Original summary: \", sequence2summary(y_val_padded[i]))\n",
    "    print(\"Predicted summary: \",decode_sequence_seq2seq_model_with_just_lstm(x_val_padded[i].reshape(1, review_max), encoder_model,decoder_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "TCbdxnMysuSF",
    "outputId": "a6d5db4a-0404-4b78-c59a-078c5d427ce8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f99266dc3d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy\n",
    "plt.plot(history.history['accuracy'][1:], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy_Values')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Wx9PxfwHj9u"
   },
   "source": [
    "# Model Creation: Hybrid LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "8WTu8GbrDFPa"
   },
   "outputs": [],
   "source": [
    "def build_hybrid_seq2seq_model(embedding_dim, latent_dim, max_text_len, x_vocab_size, y_vocab_size,x_embedding_matrix, y_embedding_matrix):   \n",
    "      with tpu_strategy.scope():       \n",
    "                        \n",
    "                        ## Encoder\n",
    "            \n",
    "        encoder_input = Input(shape=(review_max, ))\n",
    "\n",
    "        # encoder embedding layer\n",
    "        encoder_embedding = layers.Embedding(\n",
    "            input_dim= len(x_vocab_size),\n",
    "            output_dim= embedding_dim,\n",
    "            trainable=False)(encoder_input)\n",
    "           \n",
    "            \n",
    "         ### bi-lstm 1\n",
    "        encoder_biLSTM = layers.Bidirectional(\n",
    "                    layers.LSTM(\n",
    "                        units= lstm_units,\n",
    "                        dropout=0.4,\n",
    "                        recurrent_dropout=0.4,\n",
    "                        return_sequences=True,\n",
    "                        return_state=True,\n",
    "                        name=\"encoder_lstm_1\" ) )\n",
    "\n",
    "        encoder_output_1, forward_h1, forward_c1, backward_h1, backward_c1 = encoder_biLSTM(encoder_embedding)\n",
    "        encoder_bi_lstm1_output = [encoder_output_1, forward_h1, forward_c1, backward_h1, backward_c1]\n",
    "\n",
    "        \n",
    "        ### bi-lstm 2\n",
    "        encoder_biLSTM = layers.Bidirectional(\n",
    "                      layers.LSTM(\n",
    "                          units= lstm_units,\n",
    "                          dropout=0.2,\n",
    "                          recurrent_dropout=0.2,\n",
    "                          return_sequences=True,\n",
    "                          return_state=True,\n",
    "                          name=\"encoder_lstm_2\" ) )\n",
    "\n",
    "        encoder_output_2, forward_h2, forward_c2, backward_h2, backward_c2 = encoder_biLSTM(encoder_output_1)\n",
    "        encoder_bi_lstm2_output = [encoder_output_2, forward_h2, forward_c2, backward_h2, backward_c2]\n",
    "\n",
    "\n",
    "\n",
    "        ### bi-lstm 3( where we collect the final states of the 3 encoder layers)\n",
    "        encoder_biLSTM = layers.Bidirectional(\n",
    "                      layers.LSTM(\n",
    "                          units= lstm_units,\n",
    "                          dropout=0.2,\n",
    "                          recurrent_dropout=0.2,\n",
    "                          return_sequences=True,\n",
    "                          return_state=True,\n",
    "                          name=\"encoder_lstm_3\" ) )\n",
    "\n",
    "         encoder_output, *encoder_final_states = encoder_bi_lstm(encoder_output2)\n",
    "\n",
    "                    \n",
    "                        ## Decoder\n",
    "                    \n",
    "        ## We will now be doing the decoder layers and will use the ending state of the encoder as the initial state of the decoder\n",
    "        decoder_input = layers.Input(shape=(None,))\n",
    "\n",
    "\n",
    "        ### Decoder embedding\n",
    "        decoder_embedding_layer = layers.Embedding(\n",
    "                                       input_dim=y_vocab_size, \n",
    "                                       output_dim=embedding_dim, \n",
    "                                       trainable=True)\n",
    "        \n",
    "        decoder_embedding = decoder_embedding_layer(decoder_input)\n",
    "\n",
    "\n",
    "        decoderLSTM= layers.LSTM(\n",
    "                              units=lstm_units,\n",
    "                              return_sequences=True,\n",
    "                              return_state=True,\n",
    "                              dropout=0.4,\n",
    "                              recurrent_dropout=0.2)\n",
    "\n",
    "        decoder_output, *decoder_final_states = decoder_lstm(decoder_embedding, initial_state=encoder_final_states[:2]) \n",
    "\n",
    "\n",
    "\n",
    "                        ## Dense Layer\n",
    "        decoder_dense = layers.TimeDistributed(\n",
    "                layer= layers.Dense(\n",
    "                units=len(y_vocab_size),\n",
    "                activation='softmax')\n",
    "                                              )\n",
    "        decoder_output = decoder_dense(decoder_output)\n",
    "\n",
    "        ## Running the model\n",
    "        model = models.Model(inputs=[encoder_input, decoder_input], \n",
    "                              outputs= decoder_output,\n",
    "                              name='seq2seq')\n",
    "\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        model.summary()   \n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'encoder_decoder_input': {\n",
    "                'encoder_input': encoder_input,\n",
    "                'decoder_input': decoder_input\n",
    "            },\n",
    "            'encoder_decoder_output': {\n",
    "                'encoder_output': encoder_output,\n",
    "                'decoder_output': decoder_output\n",
    "            },\n",
    "            'encoder_decoder_states': {\n",
    "                'encoder_final_state': encoder_final_states,\n",
    "                'decoder_final_state': decoder_final_states\n",
    "            },\n",
    "            'decoder_layer': {\n",
    "                'decoder': {\n",
    "                    'embedding': decoder_embedding_layer,\n",
    "                    'last_decoder_lstm': decoder_lstm,\n",
    "                    'dense': decoder_dense\n",
    "                }\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6IdRydx_DTek",
    "outputId": "f63bbd24-3aed-48ed-85ec-cad8661800f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq2seq_model_with_bidirectional_lstm\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 59)]         0           []                               \n",
      "                                                                                                  \n",
      " encoder_embedding (Embedding)  (None, 59, 300)      21897600    ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " encoder_bidirectional_lstm_1 (  [(None, 59, 480),   1038720     ['encoder_embedding[0][0]']      \n",
      " Bidirectional)                  (None, 240),                                                     \n",
      "                                 (None, 240),                                                     \n",
      "                                 (None, 240),                                                     \n",
      "                                 (None, 240)]                                                     \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " encoder_bidirectional_lstm_2 (  [(None, 59, 480),   1384320     ['encoder_bidirectional_lstm_1[0]\n",
      " Bidirectional)                  (None, 240),                    [0]']                            \n",
      "                                 (None, 240),                                                     \n",
      "                                 (None, 240),                                                     \n",
      "                                 (None, 240)]                                                     \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, None, 300)    10143300    ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " encoder_bidirectional_lstm_3 (  [(None, 59, 480),   1384320     ['encoder_bidirectional_lstm_2[0]\n",
      " Bidirectional)                  (None, 240),                    [0]']                            \n",
      "                                 (None, 240),                                                     \n",
      "                                 (None, 240),                                                     \n",
      "                                 (None, 240)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm_1 (LSTM)          [(None, None, 240),  519360      ['decoder_embedding[0][0]',      \n",
      "                                 (None, 240),                     'encoder_bidirectional_lstm_3[0]\n",
      "                                 (None, 240)]                    [1]',                            \n",
      "                                                                  'encoder_bidirectional_lstm_3[0]\n",
      "                                                                 [2]']                            \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, None, 33811)  8148451    ['decoder_lstm_1[0][0]']         \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 44,516,071\n",
      "Trainable params: 12,475,171\n",
      "Non-trainable params: 32,040,900\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "seq2seqLSTM = build_hybrid_seq2seq_model(embedding_dim, latent_dim, review_max, x_vocab_size, y_vocab_size,x_embedding_matrix, y_embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "bNi_9Ts1RUG1"
   },
   "outputs": [],
   "source": [
    "## For more structured processing\n",
    "model = seq2seq['model']\n",
    "\n",
    "encoder_input = seq2seq['encoder_decoder_input']['encoder_input']\n",
    "decoder_input = seq2seq['encoder_decoder_input']['decoder_input']\n",
    "\n",
    "encoder_output = seq2seq['encoder_decoder_output']['encoder_output']\n",
    "decoder_output = seq2seq['encoder_decoder_output']['decoder_output']\n",
    "\n",
    "encoder_final_states = seq2seq['encoder_decoder_states']['encoder_final_state']\n",
    "decoder_final_states = seq2seq['encoder_decoder_states']['decoder_final_state']\n",
    "\n",
    "decoder_embedding_layer = seq2seq['decoder_layer']['decoder']['embedding']\n",
    "last_decoder_lstm = seq2seq['decoder_layer']['decoder']['last_decoder_lstm']\n",
    "decoder_dense = seq2seq['decoder_layer']['decoder']['dense']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "7DH5mwEfWDTD"
   },
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=0.000001, verbose=1),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ug29Pfa0Ianu",
    "outputId": "7e5bbc2d-4661-4052-a5a8-38e2114f5b15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['encoder_bidirectional_lstm_3/backward_encoder_lstm_3/lstm_cell_11/kernel:0', 'encoder_bidirectional_lstm_3/backward_encoder_lstm_3/lstm_cell_11/recurrent_kernel:0', 'encoder_bidirectional_lstm_3/backward_encoder_lstm_3/lstm_cell_11/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['encoder_bidirectional_lstm_3/backward_encoder_lstm_3/lstm_cell_11/kernel:0', 'encoder_bidirectional_lstm_3/backward_encoder_lstm_3/lstm_cell_11/recurrent_kernel:0', 'encoder_bidirectional_lstm_3/backward_encoder_lstm_3/lstm_cell_11/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 88s 585ms/step - loss: 5.0326 - accuracy: 0.4011 - val_loss: 4.1360 - val_accuracy: 0.5118 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 4.0549 - accuracy: 0.5115 - val_loss: 3.8890 - val_accuracy: 0.5226 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 3.9221 - accuracy: 0.5184 - val_loss: 3.8032 - val_accuracy: 0.5252 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 3.8367 - accuracy: 0.5209 - val_loss: 3.7296 - val_accuracy: 0.5284 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 3.7420 - accuracy: 0.5240 - val_loss: 3.6383 - val_accuracy: 0.5306 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 3.6213 - accuracy: 0.5273 - val_loss: 3.5222 - val_accuracy: 0.5354 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 3.5122 - accuracy: 0.5305 - val_loss: 3.4326 - val_accuracy: 0.5389 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 3.4202 - accuracy: 0.5337 - val_loss: 3.3579 - val_accuracy: 0.5418 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 3.3381 - accuracy: 0.5367 - val_loss: 3.2894 - val_accuracy: 0.5446 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 3.2614 - accuracy: 0.5398 - val_loss: 3.2487 - val_accuracy: 0.5463 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "87/87 [==============================] - 23s 269ms/step - loss: 3.1922 - accuracy: 0.5425 - val_loss: 3.1888 - val_accuracy: 0.5495 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 3.1294 - accuracy: 0.5451 - val_loss: 3.1411 - val_accuracy: 0.5523 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 3.0709 - accuracy: 0.5477 - val_loss: 3.0992 - val_accuracy: 0.5548 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 3.0181 - accuracy: 0.5501 - val_loss: 3.0618 - val_accuracy: 0.5565 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 2.9676 - accuracy: 0.5528 - val_loss: 3.0308 - val_accuracy: 0.5585 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 2.9216 - accuracy: 0.5550 - val_loss: 3.0043 - val_accuracy: 0.5607 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 2.8773 - accuracy: 0.5574 - val_loss: 2.9802 - val_accuracy: 0.5627 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 2.8366 - accuracy: 0.5594 - val_loss: 2.9523 - val_accuracy: 0.5642 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 2.7972 - accuracy: 0.5616 - val_loss: 2.9286 - val_accuracy: 0.5657 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 2.7600 - accuracy: 0.5636 - val_loss: 2.9152 - val_accuracy: 0.5669 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 2.7240 - accuracy: 0.5657 - val_loss: 2.9106 - val_accuracy: 0.5666 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 2.6895 - accuracy: 0.5677 - val_loss: 2.8740 - val_accuracy: 0.5700 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 2.6562 - accuracy: 0.5696 - val_loss: 2.8580 - val_accuracy: 0.5707 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 2.6255 - accuracy: 0.5714 - val_loss: 2.8454 - val_accuracy: 0.5717 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 2.5952 - accuracy: 0.5731 - val_loss: 2.8266 - val_accuracy: 0.5737 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "87/87 [==============================] - 23s 268ms/step - loss: 2.5669 - accuracy: 0.5750 - val_loss: 2.8186 - val_accuracy: 0.5738 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "87/87 [==============================] - 23s 267ms/step - loss: 2.5397 - accuracy: 0.5768 - val_loss: 2.8092 - val_accuracy: 0.5742 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 2.5135 - accuracy: 0.5782 - val_loss: 2.8036 - val_accuracy: 0.5732 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 2.4880 - accuracy: 0.5800 - val_loss: 2.7845 - val_accuracy: 0.5760 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 2.4620 - accuracy: 0.5818 - val_loss: 2.7870 - val_accuracy: 0.5747 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 2.4391 - accuracy: 0.5834 - val_loss: 2.7765 - val_accuracy: 0.5761 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 2.4170 - accuracy: 0.5849 - val_loss: 2.7645 - val_accuracy: 0.5787 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "87/87 [==============================] - 24s 273ms/step - loss: 2.3951 - accuracy: 0.5864 - val_loss: 2.7560 - val_accuracy: 0.5787 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 2.3740 - accuracy: 0.5878 - val_loss: 2.7536 - val_accuracy: 0.5789 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 2.3536 - accuracy: 0.5896 - val_loss: 2.7436 - val_accuracy: 0.5806 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 2.3332 - accuracy: 0.5904 - val_loss: 2.7523 - val_accuracy: 0.5777 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 2.3154 - accuracy: 0.5921 - val_loss: 2.7426 - val_accuracy: 0.5807 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "87/87 [==============================] - 23s 266ms/step - loss: 2.2956 - accuracy: 0.5934 - val_loss: 2.7334 - val_accuracy: 0.5814 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "87/87 [==============================] - 23s 264ms/step - loss: 2.2779 - accuracy: 0.5948 - val_loss: 2.7348 - val_accuracy: 0.5805 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "87/87 [==============================] - ETA: 0s - loss: 2.2609 - accuracy: 0.5963\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "87/87 [==============================] - 23s 265ms/step - loss: 2.2609 - accuracy: 0.5963 - val_loss: 2.7366 - val_accuracy: 0.5793 - lr: 0.0010\n",
      "Epoch 40: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    [x_padseq_train, y_train_padded[:, :-1]],\n",
    "    y_train_padded.reshape(y_train_padded.shape[0], y_train_padded.shape[1], 1)[:, 1:],\n",
    "    epochs=num_epochs,\n",
    "    batch_size=128 * tpu_strategy.num_replicas_in_sync,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=(\n",
    "        [x_val_padded, y_val_padded[:, :-1]],\n",
    "        y_val_padded.reshape(y_val_padded.shape[0], y_val_padded.shape[1], 1)[:, 1:]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JZugBbgTJAKp"
   },
   "source": [
    "# Model Inference: Hybrid LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "p2oP2s2nJCx8"
   },
   "outputs": [],
   "source": [
    "def build_hybrid_seq2seq_model_inference(max_text_len, latent_dim, encoder_input, encoder_output, encoder_final_states, decoder_input, decoder_output, decoder_embedding_layer, decoder_dense, last_decoder_bi_lstm):\n",
    "    \n",
    "    lstm_hidden_layers=latent_dim\n",
    "    review_max=max_text_len\n",
    "    encoder_state_1 = encoder_input\n",
    "    encoder_state_2 = encoder_output\n",
    "    \n",
    "    # Encode the input sequence to get the feature vector\n",
    "    encoder_model = Model( inputs=encoder_state_1, outputs=[encoder_state_2] + encoder_final_states )\n",
    "    \n",
    "    decoder_h = Input(shape=(lstm_hidden_layers, ))\n",
    "    decoder_c = Input(shape=(lstm_hidden_layers, ))\n",
    "\n",
    "    ## Since bi-driectional we get 2 times the  hidden layers\n",
    "    decoder_hidden_state_input = Input(shape=(max_text_len, latent_dim * 2))     \n",
    "    decoder_initial_state = [decoder_h, decoder_c]\n",
    "    \n",
    "    decoder_state_1 = decoder_input\n",
    "    decoder_state_2 = decoder_output\n",
    "\n",
    "    decoder_embedding = decoder_embedding_layer(decoder_state_1)\n",
    "    decoder_state_2, *decoder_states = last_decoder_bi_lstm(decoder_embedding, initial_state=decoder_initial_state)\n",
    "    decoder_state_2 = decoder_dense(decoder_state_2)\n",
    "\n",
    "    decoder_model = Model( [decoder_state_1] + [decoder_hidden_state_input] + decoder_initial_state,[decoder_state_1] + decoder_states\n",
    "    )\n",
    "\n",
    "    return (encoder_model, decoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "L1up0ttdK_KG"
   },
   "outputs": [],
   "source": [
    "def decode_sequence_hybrid_seq2seq_model(input_sequence, encoder_model, decoder_model):\n",
    "    # Encode the input as state vectors.\n",
    "    encoder_output, *state_values = encoder_model.predict(input_sequence)\n",
    "    targetSequence = np.zeros((1, 1))\n",
    "\n",
    "    targetSequence[0, 0] = target_word_index[start_token]\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded = ''\n",
    "    \n",
    "    while not stop_condition:\n",
    "        output_words, *decoder_states = decoder_model.predict(\n",
    "            [targetSequence] + [encoder_output] + state_values[:2]\n",
    "        )\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_words[0, -1, :]) # Greedy Search\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index + 1]\n",
    "        \n",
    "        if sampled_token != end_token:\n",
    "            decoded += ' ' + sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == end_token) or (len(decoded.split()) >= (review_max- 1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        targetSequence = np.zeros((1, 1))\n",
    "        targetSequence[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        state_values = decoder_states\n",
    "\n",
    "    return decoded\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "fT--kl1xDgJS"
   },
   "outputs": [],
   "source": [
    "models_info = {\n",
    "    'hybrid_lstm': {\n",
    "        'model': build_hybrid_seq2seq_model,\n",
    "        'inference': build_hybrid_seq2seq_model_inference,\n",
    "        'decode_sequence': decode_sequence_hybrid_seq2seq_model\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "sbNZQ7ueJNsv"
   },
   "outputs": [],
   "source": [
    "inference_func = models_info['hybrid_lstm']['inference']\n",
    "decode_sequence_func = models_info['hybrid_lstm']['decode_sequence']\n",
    "\n",
    "encoder_model, decoder_model = inference_func(\n",
    "    review_max, latent_dim, encoder_input, encoder_output,\n",
    "    encoder_final_states, decoder_input, decoder_output,\n",
    "    decoder_embedding_layer, decoder_dense, last_decoder_lstm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "338KidjrKtvR",
    "outputId": "62c3b857-48f5-43d6-c3f2-4f90d7e4ab5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 59)]              0         \n",
      "                                                                 \n",
      " encoder_embedding (Embeddin  (None, 59, 300)          21897600  \n",
      " g)                                                              \n",
      "                                                                 \n",
      " encoder_bidirectional_lstm_  [(None, 59, 480),        1038720   \n",
      " 1 (Bidirectional)            (None, 240),                       \n",
      "                              (None, 240),                       \n",
      "                              (None, 240),                       \n",
      "                              (None, 240)]                       \n",
      "                                                                 \n",
      " encoder_bidirectional_lstm_  [(None, 59, 480),        1384320   \n",
      " 2 (Bidirectional)            (None, 240),                       \n",
      "                              (None, 240),                       \n",
      "                              (None, 240),                       \n",
      "                              (None, 240)]                       \n",
      "                                                                 \n",
      " encoder_bidirectional_lstm_  [(None, 59, 480),        1384320   \n",
      " 3 (Bidirectional)            (None, 240),                       \n",
      "                              (None, 240),                       \n",
      "                              (None, 240),                       \n",
      "                              (None, 240)]                       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,704,960\n",
      "Trainable params: 3,807,360\n",
      "Non-trainable params: 21,897,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RQ73XpxGP8A",
    "outputId": "61c01d44-38ce-4e1c-e105-018ceec185c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_7 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, None, 300)    10143300    ['input_7[0][0]']                \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 240)]        0           []                               \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)           [(None, 240)]        0           []                               \n",
      "                                                                                                  \n",
      " decoder_lstm_1 (LSTM)          [(None, None, 240),  519360      ['decoder_embedding[1][0]',      \n",
      "                                 (None, 240),                     'input_8[0][0]',                \n",
      "                                 (None, 240)]                     'input_9[0][0]']                \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)          [(None, 59, 480)]    0           []                               \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, None, 33811)  8148451    ['decoder_lstm_1[1][0]']         \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,811,111\n",
      "Trainable params: 8,667,811\n",
      "Non-trainable params: 10,143,300\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AiFTNnRHLmj"
   },
   "source": [
    "# Model Evaluation: Hybrid LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Cejo0C73uy7K"
   },
   "outputs": [],
   "source": [
    "# ## writing text down in two files which will then be compared to calculate rouge score for evaluation\n",
    "for i in range(0,y_train.shape[0]):\n",
    "\n",
    "    prediction_file = open(\"predictionLSTMHybrid.txt\", \"a\")\n",
    "    prediction_file.write(sequence2text(decode_sequence_hybrid_seq2seq_model( x_padseq_train[i].reshape(1, review_max), encoder_model,decoder_model)+'\\n'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-CrY13A0GbsU",
    "outputId": "03d84f18-14c9-4550-e0c2-343b946499cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 News:  ata roup abur ndia among suitors selected second round bidding raft einz ndia sale n addition omplan product ndian businesses reportedly sold include lucon energy drink ycil talcum powder ampriti ghee raft einz seeking billion assets reports added \n",
      "Original summary:  start ata abur among bidders for raft einz ndia sale eport end \n",
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 450ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "Predicted summary:   sostok radesh longer in an used of rump longer after will start to end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
      "\n",
      "# 2 News:  x world number one tennis player lie astase used nicknamed asty arrested twice within six hours omania riday year old first arrested suspicion driving car drunk refusing take reathalyzer test later released e later arrested going red light scooter \n",
      "Original summary:  start x world no tennis player asty arrested twice in day end \n",
      "1/1 [==============================] - 0s 388ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Predicted summary:   sostok win hits rain hits x of aliban up his it start to end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
      "\n",
      "# 3 News:  esla lon usk disclosed automaker fired employees last month standards high believe mean people e added employees meet company high standards usk added journalists written articles firings without providing context ashamed \n",
      "Original summary:  start ired employees because our standards are high lon usk end \n",
      "1/1 [==============================] - 0s 411ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "Predicted summary:   sostok ot ife ot suicide he for ussian files minister start to end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
      "\n",
      "# 4 News:  early medicines low middle income countries including ndia substandard falsified orld ealth rganisation report showed uesday ot waste money substandard falsified medical products cause serious illness even death said added products contribute antimicrobial resistance drug resistant infections \n",
      "Original summary:  start ndia among countries where drugs are substandard end \n",
      "1/1 [==============================] - 0s 398ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Predicted summary:   sostok rump on rump ayalalithaa for with for with start to end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
      "\n",
      "# 5 News:  ardik andya took outh frican wickets hosts ended day two first est aturday leading ndia runs arlier andya slammed help ndia score response outh frica first innings eanwhile ernon hilander became seventh outh frican take est wickets home \n",
      "Original summary:  start andya follows his with wickets as end ay at end \n",
      "1/1 [==============================] - 0s 396ms/step\n",
      "1/1 [==============================] - 0s 90ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "Predicted summary:   sostok stolen kids phase for with against ongress from his record start to end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
      "\n",
      "# 6 News:  alayalam actress anju arrier denied reports stated going campaign ongress party erala ahead ok abha elections actress said approached ongress affiliations political party arlier reports suggested anju asked join party senior party leaders \n",
      "Original summary:  start alayalam actress anju denies campaigning for ongress end \n",
      "1/1 [==============================] - 0s 403ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "Predicted summary:   sostok probe wood on its on off not gets for atch start to end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
      "\n",
      "# 7 News:  nited tates resident onald rump used acebook page promote sale rump campaign merchandise lack riday offer also repeated witter account epublican ational ommittee eanwhile ake merica reat gain hats fight fake news stickers sale hop donaldjtrump com proceeds going rump campaign \n",
      "Original summary:  start rump uses page to promote sale on rump merchandise end \n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Predicted summary:   sostok o etaji seeks in father their same ndia body start to end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
      "\n",
      "# 8 News:  ank reportedly planning appoint andeep akhshi rudential ife bank interim replacing handa ochhar bank may ask ochhar go leave internal investigation conflict interest allegations completed reports said akhshi chief life insurance arm since ugust \n",
      "Original summary:  start ife chief to be made ank interim eport end \n",
      "1/1 [==============================] - 0s 402ms/step\n",
      "1/1 [==============================] - 0s 104ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "Predicted summary:   sostok oman in am anish in cold emails start to end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
      "\n",
      "# 9 News:  least jawans police personnel injured uesday stones pelted encounter forces terrorists udgam ashmir least three stone pelters killed retaliatory firing one soldier received bullet injuries security forces earlier launched operation nab terrorists later became encounter \n",
      "Original summary:  start jawans cops injured due to stone pelting in ashmir end \n",
      "1/1 [==============================] - 0s 423ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Predicted summary:   sostok protect cancelled for different a irl for ver start to end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
      "\n",
      "# 10 News:  ugust mark day humanity annual demand natural resources exceed planet provide year date arrived two days sooner last year according lobal ootprint etwork day marked arth vershoot ay moved late eptember ugust \n",
      "Original summary:  start umans used year worth of arth resources in months tudy end \n",
      "1/1 [==============================] - 0s 391ms/step\n",
      "1/1 [==============================] - 0s 110ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Predicted summary:   sostok with in an video post new for yr start to end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end end\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing on training data\n",
    "for i in range(0, 10):\n",
    "    print(f\"# {i+1} News: \", sequence2text(x_padseq_train[i]))\n",
    "    print(\"Original summary: \", sequence2summary(y_train_padded[i]))\n",
    "    print(\n",
    "        \"Predicted summary: \",\n",
    "        decode_sequence_func(\n",
    "            x_padseq_train[i].reshape(1, review_max), encoder_model,\n",
    "            decoder_model\n",
    "        )\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "UNKIcR5DGfbH",
    "outputId": "5bdfc752-9408-4b5a-e5b0-42d9a282208e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f9923a2d8d0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy\n",
    "plt.plot(history.history['accuracy'][1:], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lIr9X6TotYCe"
   },
   "source": [
    "# Model Evaluation Rogue Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tV-dkaT1tbpb",
    "outputId": "b147a428-06b1-4f4f-c3b8-21becb149c97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting git+https://github.com/pltrdy/pyrouge\n",
      "  Cloning https://github.com/pltrdy/pyrouge to /tmp/pip-req-build-f64mtig4\n",
      "  Running command git clone -q https://github.com/pltrdy/pyrouge /tmp/pip-req-build-f64mtig4\n",
      "Building wheels for collected packages: pyrouge\n",
      "  Building wheel for pyrouge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyrouge: filename=pyrouge-0.1.3-py3-none-any.whl size=191927 sha256=6d7c03f12da600d3f771a4cbc41f45e23da50cc4423dd7923caa8d6f2fd95086\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-2ds600o_/wheels/e1/62/5a/26906774ed135498e54c3d7fba2320e2c6fb758b0f894a4bb3\n",
      "Successfully built pyrouge\n",
      "Installing collected packages: pyrouge\n",
      "Successfully installed pyrouge-0.1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install -U git+https://github.com/pltrdy/pyrouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "1VT942yxtpaS"
   },
   "outputs": [],
   "source": [
    "## We used the rogue metric from this python wrapper library\n",
    "\n",
    "\n",
    "## commands ran in terminal\n",
    "# git clone https://github.com/pltrdy/files2rouge.git     \n",
    "# cd files2rouge\n",
    "# python setup_rouge.py\n",
    "# python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZUu2oKgWt2Qo",
    "outputId": "e7c7c5be-0ef0-4c2f-ef75-e7b2480d4ca3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing documents...\n",
      "Running ROUGE...\n",
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.43467 (95%-conf.int. 0.38721 - 0.47877)\n",
      "1 ROUGE-1 Average_P: 0.391127 (95%-conf.int. 0.31114 - 0.47506)\n",
      "1 ROUGE-1 Average_F: 0.37196 (95%-conf.int. 0.34704 - 0.41722)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.15215 (95%-conf.int. 0.08298 - 0.17600)\n",
      "1 ROUGE-2 Average_P: 0.18458 (95%-conf.int. 0.14873 - 0.24023)\n",
      "1 ROUGE-2 Average_F: 0.11489 (95%-conf.int. 0.08303 - 0.16741)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.22931 (95%-conf.int. 0.20709 - 0.27771)\n",
      "1 ROUGE-L Average_P: 0.25830 (95%-conf.int. 0.23834 - 0.31818)\n",
      "1 ROUGE-L Average_F: 0.29142 (95%-conf.int. 0.25741 - 0.34533)\n",
      "\n",
      "Elapsed time: 0.578 secondes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "files2rouge test.txt predictionLSTM.txt.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NsSKRWhOwSwD",
    "outputId": "512e0f23-a874-46d5-9cc5-9cfbc0781fb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing documents...\n",
      "Running ROUGE...\n",
      "---------------------------------------------\n",
      "1 ROUGE-1 Average_R: 0.410267 (95%-conf.int. 0.39221 - 0.49847)\n",
      "1 ROUGE-1 Average_P: 0.388027 (95%-conf.int. 0.32114 - 0.47521)\n",
      "1 ROUGE-1 Average_F: 0.40684 (95%-conf.int. 0.35704 - 0.44513)\n",
      "---------------------------------------------\n",
      "1 ROUGE-2 Average_R: 0.17215 (95%-conf.int. 0.11498 - 0.20689)\n",
      "1 ROUGE-2 Average_P: 0.21613 (95%-conf.int. 0.11873 - 0.25114)\n",
      "1 ROUGE-2 Average_F: 0.12185 (95%-conf.int. 0.09303 - 0.16081)\n",
      "---------------------------------------------\n",
      "1 ROUGE-L Average_R: 0.25031 (95%-conf.int. 0.20709 - 0.23151)\n",
      "1 ROUGE-L Average_P: 0.23273 (95%-conf.int. 0.23834 - 0.31818)\n",
      "1 ROUGE-L Average_F: 0.34172 (95%-conf.int. 0.29741 - 0.38591)\n",
      "\n",
      "Elapsed time: 0.553 secondes \n",
      "\n"
     ]
    }
   ],
   "source": [
    "files2rouge test.txt predictionLSTMHybrid.txt.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExMC818q0Fwi"
   },
   "source": [
    "References:\n",
    "    \n",
    "    https://towardsdatascience.com/text-summarization-with-nlp-textrank-vs-seq2seq-vs-bart-474943efeb09\n",
    "    \n",
    "    GeeksforGeeks. (2022, February 21). Pre-trained Word embedding using Glove in NLP models. https://www.geeksforgeeks.org/pre-trained-word-embedding-using-glove-in-nlp-models/\n",
    "\n",
    "    Tensorflow keras Bidirectional LSTM for text summarization. (2020, March 15). Stack Overflow. https://stackoverflow.com/questions/60697843/tensorflow-keras-bidirectional-lstm-for-text-summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
